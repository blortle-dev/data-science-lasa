{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Predicting Bitcoin Prices with NNs\n",
    "\n",
    "In this project, I'll build a neural network to predict the price of bitcoin.\n",
    "To do this, I'll use the Open, Close, High, Low, and Volume values from a dataset I found on Kaggle."
   ],
   "id": "be314bca6a2f24eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T18:32:11.365867Z",
     "start_time": "2025-05-22T18:32:11.362855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# importing\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "cc642dba288d0c49",
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now that everything's imported, I can start to import my data. For this project, the dataset is very large (nearly 400MB), and waaaay over GitHub's 30MB file size limit. To get around this, I've run the entire NN on my own device instead of Google Colab. If you want to run this on your own, you can find the dataset [here](https://www.kaggle.com/datasets/mczielinski/bitcoin-historical-data). It's also got over 7,000,000 rows, so I'll need to trim that down. In order to trim this down, I'll only choose rows that have over 200 volume. Why 200? When I looked at the original data, I saw that most of the entries remained below 200 volume, so I was able to eliminate a *lot* of unnecessary data. (brought it from 7M -> 5M rows with volume > 1, and from 5M -> 13,000 with volume > 200) This should significantly help my model to run faster.",
   "id": "a7566f2fecbe5a78"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T18:32:13.080826Z",
     "start_time": "2025-05-22T18:32:11.390006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"btcusd_1-min_data.csv\").dropna()\n",
    "#drops all the non-numerical columns\n",
    "\n",
    "# We won't be needing the timestamps in the NN, and it's not numerical.\n",
    "df.drop(columns=[\"Timestamp\"],inplace=True)\n",
    "\n",
    "df.query(\"Volume > 200\", inplace=True) # Brings our row count from 7,000,000+ to just over 13,000.\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "df"
   ],
   "id": "75db6e74aaa1e517",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           Open      High       Low     Close      Volume\n",
       "0          5.37      5.37      5.37      5.37  213.465156\n",
       "1          5.33      5.33      5.33      5.33  247.560124\n",
       "2          5.32      5.32      5.32      5.32  233.772116\n",
       "3          4.90      4.90      4.90      4.90  233.890000\n",
       "4          5.12      5.12      5.12      5.12  233.520000\n",
       "...         ...       ...       ...       ...         ...\n",
       "13566  26882.00  27190.00  26870.00  27075.00  210.505204\n",
       "13567  33175.00  33175.00  32873.00  32887.00  200.290325\n",
       "13568  46070.00  46070.00  44903.00  45643.00  339.941471\n",
       "13569  62119.00  62530.00  61971.00  62393.00  233.090748\n",
       "13570  96410.00  96410.00  92092.00  92957.00  325.202458\n",
       "\n",
       "[13571 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.37</td>\n",
       "      <td>5.37</td>\n",
       "      <td>5.37</td>\n",
       "      <td>5.37</td>\n",
       "      <td>213.465156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.33</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.33</td>\n",
       "      <td>247.560124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.32</td>\n",
       "      <td>5.32</td>\n",
       "      <td>5.32</td>\n",
       "      <td>5.32</td>\n",
       "      <td>233.772116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.90</td>\n",
       "      <td>4.90</td>\n",
       "      <td>4.90</td>\n",
       "      <td>4.90</td>\n",
       "      <td>233.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.12</td>\n",
       "      <td>5.12</td>\n",
       "      <td>5.12</td>\n",
       "      <td>5.12</td>\n",
       "      <td>233.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13566</th>\n",
       "      <td>26882.00</td>\n",
       "      <td>27190.00</td>\n",
       "      <td>26870.00</td>\n",
       "      <td>27075.00</td>\n",
       "      <td>210.505204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13567</th>\n",
       "      <td>33175.00</td>\n",
       "      <td>33175.00</td>\n",
       "      <td>32873.00</td>\n",
       "      <td>32887.00</td>\n",
       "      <td>200.290325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13568</th>\n",
       "      <td>46070.00</td>\n",
       "      <td>46070.00</td>\n",
       "      <td>44903.00</td>\n",
       "      <td>45643.00</td>\n",
       "      <td>339.941471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13569</th>\n",
       "      <td>62119.00</td>\n",
       "      <td>62530.00</td>\n",
       "      <td>61971.00</td>\n",
       "      <td>62393.00</td>\n",
       "      <td>233.090748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13570</th>\n",
       "      <td>96410.00</td>\n",
       "      <td>96410.00</td>\n",
       "      <td>92092.00</td>\n",
       "      <td>92957.00</td>\n",
       "      <td>325.202458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13571 rows Ã— 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "My first time through, I made this model:",
   "id": "7a1537029bd0f445"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T18:32:13.142454Z",
     "start_time": "2025-05-22T18:32:13.122713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "shoot = df[[\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"]]\n",
    "\n",
    "#convert to numpy array\n",
    "s_matrix = shoot.to_numpy()\n",
    "#convert to a PyTorch tensor\n",
    "s_tensor = torch.from_numpy(s_matrix)\n",
    "\n",
    "#this function defaults to a random  offset vector and weight matrix\n",
    "linear = torch.nn.Linear(in_features=2, # in_features: must match column number of input\n",
    "                         out_features=1,# out_features: column number of output\n",
    "                         dtype=torch.float64) #specifies the data type\n",
    "\n",
    "X = s_tensor[:,[1,2]] #use 3PA and FT% to predict\n",
    "y_pred = linear(X) #the actual matrix multiplication\n",
    "print(f\"Input shape: {X.shape}\\n\")\n",
    "print(f\"Output:\\n{y_pred}\\n\\nOutput shape: {y_pred.shape}\")\n",
    "\n",
    "X = s_tensor[:,2].unsqueeze(dim=1) #use FT% as a predictor\n",
    "y = s_tensor[:,0].unsqueeze(dim=1) #FG% is the estimand, the thing we're predicting.\n",
    "\n",
    "# 80% of data is training, 20% is testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "#this function defaults to a random  offset vector and weight matrix\n",
    "linear = torch.nn.Linear(\n",
    "    in_features=1, # in_features: must match number of columns of input, which is now one\n",
    "    out_features=1,# out_features: number of columns in output\n",
    "    dtype=torch.float64) #specifies the data type\n",
    "\n",
    "# Create a loss function\n",
    "loss_fn = nn.MSELoss() # mean squared error; this is similar to multiplying our matrix by itself\n",
    "\n",
    "# Create an optimizer; SGD is stochastic gradient decent\n",
    "optimizer = torch.optim.SGD(params=linear.parameters(),\n",
    "                            lr=0.1) #this is how fast it optimizes; smaller is slower, but more consistent\n",
    "\n",
    "# Set the number of epochs; this is how many times we update our model\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ### Training\n",
    "    #this allows our matrices to update\n",
    "    linear.train()\n",
    "    # 1. Forward pass; makes predictions\n",
    "    y_pred = linear(X_train)\n",
    "    # 2. Calculate loss; how bad were our predictions?\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    # 3. Optimizer zero grad; resets how we change our model\n",
    "    optimizer.zero_grad()\n",
    "    # 4. Loss backwards; determines how to change our weights matrix\n",
    "    loss.backward()\n",
    "    # 5. Optimizer step; changes our weights matrix based on .backward()\n",
    "    optimizer.step()\n",
    "    ### Testing\n",
    "    linear.eval() #forces our matrices to stay the same\n",
    "    with torch.inference_mode():\n",
    "      # 1. Forward pass; makes predictions, but with test data\n",
    "      test_pred = linear(X_test)\n",
    "      # 2. Calculate the loss, but with test data\n",
    "      test_loss = loss_fn(test_pred, y_test)\n",
    "    # Print out what's happening\n",
    "    if epoch % 1 == 0: #prints every 100 epochs\n",
    "        print(f\"Epoch: {epoch} | Train loss: {loss:.5f}, Test loss: {test_loss:.5f}\")"
   ],
   "id": "e9d89ea0ff49950b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([13571, 2])\n",
      "\n",
      "Output:\n",
      "tensor([[2.7933e+00],\n",
      "        [2.7675e+00],\n",
      "        [2.7610e+00],\n",
      "        ...,\n",
      "        [2.9665e+04],\n",
      "        [4.0292e+04],\n",
      "        [6.2029e+04]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Output shape: torch.Size([13571, 1])\n",
      "Epoch: 0 | Train loss: 55386828.51582, Test loss: 817501361313578745856.00000\n",
      "Epoch: 1 | Train loss: 668130026742748807168.00000, Test loss: 9862384608431036967817359602483200.00000\n",
      "Epoch: 2 | Train loss: 8060360014876026943691928612372480.00000, Test loss: 118980389096827792977166417950862398601115467776.00000\n",
      "Epoch: 3 | Train loss: 97240658208626681239687741803690121206228320256.00000, Test loss: 1435386425462542279385225043254206663385636574030832376741888.00000\n",
      "Epoch: 4 | Train loss: 1173117030926122753649028844273178063140717156000652121341952.00000, Test loss: 17316586422703717248329872569560672971294784764467707805919046360801214464.00000\n",
      "Epoch: 5 | Train loss: 14152552991736452380036353934215756057227503958430691380329989249022558208.00000, Test loss: 208908319053063527629936556063855356689712809167304023617957794574858326686383443279872.00000\n",
      "Epoch: 6 | Train loss: 170737233288467184089199067495910394435743917143975645174976044763216691163757656670208.00000, Test loss: 2520282271819851030891569988739197301707693092421767222867527348593222846823916459263918101810380800.00000\n",
      "Epoch: 7 | Train loss: 2059784043770868340331654788017924429920581160705411330873420877305372053755664194792948084336754688.00000, Test loss: 30404833845013572861561812275526317638618428961178175281164961848898591443846867739933671862782302644611854630912.00000\n",
      "Epoch: 8 | Train loss: 24849356085118706026422774911764874465748788515515308315142832868088517634385991785777772971259911409585035935744.00000, Test loss: 366805707233480123527640114875411777879958716901698195453414488348579926219063199036959766334632402666463381795377018107330560.00000\n",
      "Epoch: 9 | Train loss: 299784096159216472036692017389887366365467511424142684950042007739450037010112872011758583368255561909348479174580990266834944.00000, Test loss: 4425165667567647113123574640955239251294753712861979182919317151186381560483602353224017115315981567405445244786241161926552923007071813632.00000\n"
     ]
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As we can see, it looks horrible! Then, I found out I forgot to normalize my data. (thanks Grant!) So, I added some new code to normalize it. Now, I'll continue going through each step of making the NN.",
   "id": "4c42d5a6548d2cce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T18:32:13.182992Z",
     "start_time": "2025-05-22T18:32:13.176361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Alternative way to normalize the data, stolen from GeeksForGeeks (source at the bottom)\n",
    "\n",
    "z_scaled = df.copy()\n",
    "\n",
    "for column in z_scaled.columns:\n",
    "    z_scaled[column] = (z_scaled[column] - z_scaled[column].mean()) / z_scaled[column].std()\n",
    "\n",
    "shoot = z_scaled[[\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"]]"
   ],
   "id": "777b5a0340cdddb2",
   "outputs": [],
   "execution_count": 97
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This code is just setting all the data up to make the NN, and is identical to what we used in the NN where I forgot to normalize the data.",
   "id": "c6568374a250711e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T18:32:13.252504Z",
     "start_time": "2025-05-22T18:32:13.249789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#convert to numpy array\n",
    "s_matrix = shoot.to_numpy()\n",
    "#convert to a PyTorch tensor\n",
    "s_tensor = torch.from_numpy(s_matrix)"
   ],
   "id": "1c5f5b7711ac0462",
   "outputs": [],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T18:32:13.276308Z",
     "start_time": "2025-05-22T18:32:13.271501Z"
    }
   },
   "cell_type": "code",
   "source": "s_tensor #the default data type is a float",
   "id": "e9a5971e50275e1d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.2245e-01, -4.2206e-01, -4.2482e-01, -4.2344e-01, -5.9415e-01],\n",
       "        [-4.2246e-01, -4.2207e-01, -4.2483e-01, -4.2345e-01, -4.3966e-01],\n",
       "        [-4.2246e-01, -4.2208e-01, -4.2483e-01, -4.2345e-01, -5.0213e-01],\n",
       "        ...,\n",
       "        [ 1.1179e+01,  1.1117e+01,  1.1033e+01,  1.1119e+01, -2.1062e-02],\n",
       "        [ 1.5221e+01,  1.5241e+01,  1.5388e+01,  1.5356e+01, -5.0522e-01],\n",
       "        [ 2.3857e+01,  2.3728e+01,  2.3075e+01,  2.3086e+01, -8.7847e-02]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T18:32:13.320830Z",
     "start_time": "2025-05-22T18:32:13.316444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#copied from pytorch fundamentals' online textbook\n",
    "\n",
    "#this function defaults to a random  offset vector and weight matrix\n",
    "linear = torch.nn.Linear(in_features=4, # in_features: must match column number of input\n",
    "                         out_features=3,# out_features: column number of output\n",
    "                         dtype=torch.float64) #specifies the data type\n",
    "\n",
    "X = s_tensor[:,[0,1,2,4]] #use everything but close to predict\n",
    "y_pred = linear(X) #the actual matrix multiplication\n",
    "print(f\"Input shape: {X.shape}\\n\")\n",
    "print(f\"Output:\\n{y_pred}\\n\\nOutput shape: {y_pred.shape}\")"
   ],
   "id": "9a2fd65dd60cc655",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([13571, 4])\n",
      "\n",
      "Output:\n",
      "tensor([[  0.3059,   0.3355,  -0.2668],\n",
      "        [  0.2597,   0.3175,  -0.3033],\n",
      "        [  0.2784,   0.3248,  -0.2885],\n",
      "        ...,\n",
      "        [  8.5967,  -6.2732,   7.6564],\n",
      "        [ 11.6901,  -8.6270,  10.7057],\n",
      "        [ 17.9166, -13.1920,  16.2854]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Output shape: torch.Size([13571, 3])\n"
     ]
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "All I've changed is the predictors and estimands here, otherwise it's identical to the notes.",
   "id": "5ad5ad9e43631ae1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T18:32:13.362700Z",
     "start_time": "2025-05-22T18:32:13.359709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = s_tensor[:,4].unsqueeze(dim=1) #use FT% as a predictor\n",
    "y = s_tensor[:,3].unsqueeze(dim=1) #FG% is the estimand, the thing we're predicting.\n",
    "\n",
    "# 80% of data is training, 20% is testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ],
   "id": "a24c102cb642fc83",
   "outputs": [],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T18:32:13.391194Z",
     "start_time": "2025-05-22T18:32:13.388553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#this function defaults to a random  offset vector and weight matrix\n",
    "linear = torch.nn.Linear(\n",
    "    in_features=1, # in_features: must match number of columns of input, which is now one\n",
    "    out_features=1,# out_features: number of columns in output\n",
    "    dtype=torch.float64) #specifies the data type"
   ],
   "id": "7b719ba8d47d8488",
   "outputs": [],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T18:32:13.409810Z",
     "start_time": "2025-05-22T18:32:13.407419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a loss function\n",
    "loss_fn = nn.MSELoss() # mean squared error; this is similar to multiplying our matrix by itself\n",
    "\n",
    "# Create an optimizer; SGD is stochastic gradient decent\n",
    "optimizer = torch.optim.SGD(params=linear.parameters(),\n",
    "                            lr=0.1) #this is how fast it optimizes; smaller is slower, but more consistent"
   ],
   "id": "31346d4418871dcb",
   "outputs": [],
   "execution_count": 103
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now that everything for our neural network has been prepared, we're all good to start modeling this. I'll be using 10 epochs, since that's what the notes recommended.",
   "id": "9bdbe44693199324"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T18:32:13.435441Z",
     "start_time": "2025-05-22T18:32:13.428257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set the number of epochs; this is how many times we update our model\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ### Training\n",
    "\n",
    "    #this allows our matrices to update\n",
    "    linear.train()\n",
    "\n",
    "    # 1. Forward pass; makes predictions\n",
    "    y_pred = linear(X_train)\n",
    "\n",
    "    # 2. Calculate loss; how bad were our predictions?\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "    # 3. Optimizer zero grad; resets how we change our model\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Loss backwards; determines how to change our weights matrix\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Optimizer step; changes our weights matrix based on .backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    ### Testing\n",
    "    linear.eval() #forces our matrices to stay the same\n",
    "    with torch.inference_mode():\n",
    "      # 1. Forward pass; makes predictions, but with test data\n",
    "      test_pred = linear(X_test)\n",
    "      # 2. Calculate the loss, but with test data\n",
    "      test_loss = loss_fn(test_pred, y_test)\n",
    "\n",
    "    # Print out what's happening\n",
    "    if epoch % 1 == 0: #prints every 100 epochs\n",
    "        print(f\"Epoch: {epoch} | Train loss: {loss:.5f}, Test loss: {test_loss:.5f}\")\n"
   ],
   "id": "5762efea484913f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train loss: 1.80235, Test loss: 1.51986\n",
      "Epoch: 1 | Train loss: 1.50583, Test loss: 1.33622\n",
      "Epoch: 2 | Train loss: 1.31617, Test loss: 1.21953\n",
      "Epoch: 3 | Train loss: 1.19486, Test loss: 1.14553\n",
      "Epoch: 4 | Train loss: 1.11727, Test loss: 1.09870\n",
      "Epoch: 5 | Train loss: 1.06764, Test loss: 1.06914\n",
      "Epoch: 6 | Train loss: 1.03590, Test loss: 1.05056\n",
      "Epoch: 7 | Train loss: 1.01560, Test loss: 1.03894\n",
      "Epoch: 8 | Train loss: 1.00261, Test loss: 1.03171\n",
      "Epoch: 9 | Train loss: 0.99431, Test loss: 1.02725\n"
     ]
    }
   ],
   "execution_count": 104
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This looks promising! Let's check the final graph and results from this NN.",
   "id": "e27b53759563d7e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T18:32:13.484320Z",
     "start_time": "2025-05-22T18:32:13.477202Z"
    }
   },
   "cell_type": "code",
   "source": "shoot",
   "id": "423d3d1192de0c3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Open       High        Low      Close    Volume\n",
       "0      -0.422449  -0.422065  -0.424822  -0.423439 -0.594147\n",
       "1      -0.422460  -0.422075  -0.424832  -0.423449 -0.439657\n",
       "2      -0.422462  -0.422077  -0.424835  -0.423452 -0.502133\n",
       "3      -0.422568  -0.422183  -0.424942  -0.423558 -0.501599\n",
       "4      -0.422512  -0.422127  -0.424886  -0.423502 -0.503275\n",
       "...          ...        ...        ...        ...       ...\n",
       "13566   6.346376   6.387903   6.430852   6.423038 -0.607559\n",
       "13567   7.931255   7.887193   7.962778   7.893015 -0.653845\n",
       "13568  11.178835  11.117494  11.032754  11.119275 -0.021062\n",
       "13569  15.220743  15.240856  15.388393  15.355701 -0.505220\n",
       "13570  23.856863  23.728067  23.075072  23.085978 -0.087847\n",
       "\n",
       "[13571 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.422449</td>\n",
       "      <td>-0.422065</td>\n",
       "      <td>-0.424822</td>\n",
       "      <td>-0.423439</td>\n",
       "      <td>-0.594147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.422460</td>\n",
       "      <td>-0.422075</td>\n",
       "      <td>-0.424832</td>\n",
       "      <td>-0.423449</td>\n",
       "      <td>-0.439657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.422462</td>\n",
       "      <td>-0.422077</td>\n",
       "      <td>-0.424835</td>\n",
       "      <td>-0.423452</td>\n",
       "      <td>-0.502133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.422568</td>\n",
       "      <td>-0.422183</td>\n",
       "      <td>-0.424942</td>\n",
       "      <td>-0.423558</td>\n",
       "      <td>-0.501599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.422512</td>\n",
       "      <td>-0.422127</td>\n",
       "      <td>-0.424886</td>\n",
       "      <td>-0.423502</td>\n",
       "      <td>-0.503275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13566</th>\n",
       "      <td>6.346376</td>\n",
       "      <td>6.387903</td>\n",
       "      <td>6.430852</td>\n",
       "      <td>6.423038</td>\n",
       "      <td>-0.607559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13567</th>\n",
       "      <td>7.931255</td>\n",
       "      <td>7.887193</td>\n",
       "      <td>7.962778</td>\n",
       "      <td>7.893015</td>\n",
       "      <td>-0.653845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13568</th>\n",
       "      <td>11.178835</td>\n",
       "      <td>11.117494</td>\n",
       "      <td>11.032754</td>\n",
       "      <td>11.119275</td>\n",
       "      <td>-0.021062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13569</th>\n",
       "      <td>15.220743</td>\n",
       "      <td>15.240856</td>\n",
       "      <td>15.388393</td>\n",
       "      <td>15.355701</td>\n",
       "      <td>-0.505220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13570</th>\n",
       "      <td>23.856863</td>\n",
       "      <td>23.728067</td>\n",
       "      <td>23.075072</td>\n",
       "      <td>23.085978</td>\n",
       "      <td>-0.087847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13571 rows Ã— 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T18:32:13.528542Z",
     "start_time": "2025-05-22T18:32:13.524250Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_predictions(train_data=X_train,\n",
    "                     train_labels=y_train,\n",
    "                     test_data=X_test,\n",
    "                     test_labels=y_test,\n",
    "                     predictions=None):\n",
    "  \"\"\"\n",
    "  Plots training data, test data and compares predictions.\n",
    "  \"\"\"\n",
    "\n",
    "  # Plot training data in blue\n",
    "  plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
    "\n",
    "  # Plot test data in green\n",
    "  plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n",
    "\n",
    "  if predictions is not None:\n",
    "    # Plot the predictions in red (predictions were made on the test data)\n",
    "    plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
    "\n",
    "  # Show the legend\n",
    "  plt.legend(prop={\"size\": 14});"
   ],
   "id": "a7655eba3f53ce45",
   "outputs": [],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T18:32:13.672630Z",
     "start_time": "2025-05-22T18:32:13.563167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Turn on evaluation mode\n",
    "linear.eval()\n",
    "\n",
    "# Make predictions (inference)\n",
    "with torch.inference_mode():\n",
    "    y_preds = linear(X_test)\n",
    "\n",
    "# Plot data and predictions\n",
    "plot_predictions(predictions=y_preds);"
   ],
   "id": "384e2241b0a72953",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 107
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Interesting.. I'll try making a multi-layered NN using the code from the Unit9Notes. There's not too much to say here, so I'll just show all the code to get to the model and analyze both models in the conclusion section.",
   "id": "478ce1bc8ae42252"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T18:32:15.251580Z",
     "start_time": "2025-05-22T18:32:13.735476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df2 = pd.read_csv(\"btcusd_1-min_data.csv\")\n",
    "\n",
    "#just gonna trim off some unnecessary data here\n",
    "\n",
    "# We won't be needing the timestamps in the NN, and it's not numerical.\n",
    "df2.drop(columns=[\"Timestamp\"],inplace=True)\n",
    "\n",
    "df2.query(\"Volume > 200\", inplace=True) # Brings our row count from 7,000,000+ to just over 13,000.\n",
    "df2.reset_index(drop=True,inplace=True)\n",
    "\n",
    "#convert to a PyTorch tensor\n",
    "h = df2.Volume.to_numpy() #just gonna use volume to predict\n",
    "height = torch.from_numpy(h)\n",
    "w = df2.Close.to_numpy()\n",
    "weight = torch.from_numpy(w)"
   ],
   "id": "adb0a7dff11d86f0",
   "outputs": [],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T18:32:15.270347Z",
     "start_time": "2025-05-22T18:32:15.267931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = height.unsqueeze(dim=1) #use height as a predictor\n",
    "y = weight.unsqueeze(dim=1) #weight is the estimand, the thing we're predicting."
   ],
   "id": "fbc0305db3ca0f3d",
   "outputs": [],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T18:32:15.295Z",
     "start_time": "2025-05-22T18:32:15.287611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Scale the height using standardization\n",
    "scaler = StandardScaler()\n",
    "height_scaled = scaler.fit_transform(\n",
    "    height.reshape(-1, 1) #makes it a column vector\n",
    "    )\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    height_scaled, weight, test_size=0.2,\n",
    ")\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)"
   ],
   "id": "a1290c966e0772ba",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_z/2t3c57x51dx053zg79bk54vr0000gn/T/ipykernel_49768/4067959083.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train = torch.tensor(y_train, dtype=torch.float32)\n",
      "/var/folders/_z/2t3c57x51dx053zg79bk54vr0000gn/T/ipykernel_49768/4067959083.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test = torch.tensor(y_test, dtype=torch.float32)\n"
     ]
    }
   ],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T18:32:15.320180Z",
     "start_time": "2025-05-22T18:32:15.317488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Two layer nn with nn.Sequential\n",
    "model_00 = nn.Sequential(\n",
    "    #out_features is 7, for 7 nodes/neurons/knots\n",
    "    nn.Linear(in_features=1, out_features=7),\n",
    "    #in_features is 7, for 7 nodes/neurons/knots\n",
    "    nn.Linear(in_features=7, out_features=1),\n",
    ")"
   ],
   "id": "30a2b2330fd4a22a",
   "outputs": [],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T18:32:15.339153Z",
     "start_time": "2025-05-22T18:32:15.336324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a loss function\n",
    "# different loss functions work better for different data sets\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Create an optimizer; SGD is stochastic gradient decent\n",
    "#Adam is another similar, popular optimizer\n",
    "optimizer = torch.optim.SGD(params=model_00.parameters(),\n",
    "                            lr=0.0001) #this is how fast it optimizes; smaller is slower, but more consistent"
   ],
   "id": "503347f3308a6001",
   "outputs": [],
   "execution_count": 112
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Model time!",
   "id": "310db579cea6b2e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T18:32:20.694071Z",
     "start_time": "2025-05-22T18:32:15.357654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set the number of epochs; this is how many times we update our model\n",
    "epochs = 2000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ### Training\n",
    "\n",
    "    #this allows our matrices to update\n",
    "    model_00.train()\n",
    "\n",
    "    # 1. Forward pass; makes predictions\n",
    "    y_pred = model_00(X_train)\n",
    "\n",
    "    # 2. Calculate loss; how bad were our predictions?\n",
    "    loss = loss_fn(y_pred.squeeze(), y_train)\n",
    "\n",
    "    # 3. Optimizer zero grad; resets how we change our model\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Loss backwards; determines how to change our weights matrix\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Optimizer step; changes our weights matrix based on .backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    ### Testing\n",
    "    model_00.eval() #forces our matrices to stay the same\n",
    "    with torch.inference_mode():\n",
    "      # 1. Forward pass; makes predictions, but with test data\n",
    "      test_pred = model_00(X_test)\n",
    "      # 2. Calculate the loss, but with test data\n",
    "      test_loss = loss_fn(test_pred, y_test)\n",
    "\n",
    "    # Print out what's happening\n",
    "    if epoch % 200 == 0: #prints every 200 epochs\n",
    "        print(f\"Epoch: {epoch} | Train loss: {loss:.5f}, Test loss: {test_loss:.5f}\")"
   ],
   "id": "426807b97ae228ca",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([2715])) that is different to the input size (torch.Size([2715, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train loss: 18579588.00000, Test loss: 17940910.00000\n",
      "Epoch: 200 | Train loss: 15578185.00000, Test loss: 15279790.00000\n",
      "Epoch: 400 | Train loss: 15578185.00000, Test loss: 15279790.00000\n",
      "Epoch: 600 | Train loss: 15578185.00000, Test loss: 15279790.00000\n",
      "Epoch: 800 | Train loss: 15578185.00000, Test loss: 15279790.00000\n",
      "Epoch: 1000 | Train loss: 15578185.00000, Test loss: 15279790.00000\n",
      "Epoch: 1200 | Train loss: 15578185.00000, Test loss: 15279790.00000\n",
      "Epoch: 1400 | Train loss: 15578185.00000, Test loss: 15279790.00000\n",
      "Epoch: 1600 | Train loss: 15578185.00000, Test loss: 15279790.00000\n",
      "Epoch: 1800 | Train loss: 15578185.00000, Test loss: 15279790.00000\n"
     ]
    }
   ],
   "execution_count": 113
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Oop.. That doesn't look good. Maybe I'll stick to the single-layered neural network.",
   "id": "621907dd1ea3763a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "The single-layered neural network performed better than the multi-layered one. My best guess as to why is that the  multi-layered model was only able to use one predictor, while I was able to use 4 on the single-layered model. I didn't have enough time to tweak the mult-layered model to improve it, so this is the best NN I'll have for this project. If I were to redo this, I'd spend more time on the multi-layered model to further improve it. The single-layered NN didn't end up as bad as I'd expected though, so I'm overall happy with this project."
   ],
   "id": "a58763b92080865b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Sources\n",
    "\n",
    "Stole some normalization code from [here](https://www.geeksforgeeks.org/data-normalization-with-pandas/)."
   ],
   "id": "c0bd6c5f7df68025"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
